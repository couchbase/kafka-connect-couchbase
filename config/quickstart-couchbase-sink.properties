# Arbitrary unique name for the connector. Attempting to register
# two connectors with the same name will fail.
name=test-couchbase-sink

# The Java class for the connector.
connector.class=com.couchbase.connect.kafka.CouchbaseSinkConnector

# The maximum number of tasks that should be created for this connector.
tasks.max=2

# Read from these Kafka topics (comma-separated list).
topics=couchbase-sink-example

# Connect to this Couchbase cluster (comma-separated list of bootstrap nodes).
couchbase.seed.nodes=127.0.0.1
couchbase.bootstrap.timeout=10s

# Optionally connect to Couchbase Server over a secure channel.
# If the KAFKA_COUCHBASE_TRUST_STORE_PASSWORD environment variable is set,
# it will override the password specified here.
#   couchbase.enable.tls=true
#   couchbase.trust.store.path=/path/to/keystore
#   couchbase.trust.store.password=secret

# Write to this Couchbase bucket using these credentials.
# If the KAFKA_COUCHBASE_PASSWORD environment variable is set,
# it will override the password specified here.
couchbase.bucket=default
couchbase.username=Administrator
couchbase.password=password

# Optionally set the Couchbase document ID from fields of the message body.
# The value is a format string with a placeholder for each field to include
# in the ID. A placeholder looks like "${/path/to/field}" where the path is
# specified as a JSON pointer. Examples:
#   couchbase.document.id=${/id}
#   couchbase.document.id=invoice::${/id}
#   couchbase.document.id=${/metadata/type}::${/id}

# Optionally remove the ID fields from the document before saving to Couchbase.
#   couchbase.remove.document.id=true

# The preferred way to specify an enhanced durability requirement when using Couchbase Server 6.5 or later.
# The default value of NONE means a write is considered successful as soon as it reaches the memory of the active node.
# Valid Values: One of [NONE, MAJORITY, MAJORITY_AND_PERSIST_TO_ACTIVE, PERSIST_TO_MAJORITY]
couchbase.durability=NONE

# Optionally specify Couchbase persistence requirements for a write to be
# considered successful. Default is NONE. Other values enhance durability
# but reduce performance. If the requested requirements cannot be met
# (due to Couchbase rebalance or failover, for instance) the connector will
# terminate. Possible values:
#  NONE   - Do not require any disk persistence.
#  MASTER - Require disk persistence to the master node of the document only.
#  ONE    - Require disk persistence of one node (master or replica).
#  TWO    - Require disk persistence of two nodes (master or replica).
#  THREE  - Require disk persistence of three nodes (master or replica).
#  FOUR   - Require disk persistence of four nodes (master + three replicas).
#   couchbase.persist.to=NONE

# Optionally specify Couchbase replication requirements for a write to be
# considered successful. Default is NONE. Other values enhance durability
# but reduce performance. If the requested requirements cannot be met
# (due to Couchbase rebalance or failover, for instance) the connector will
# terminate. Possible values:
#   NONE   - Do not require any replication.
#   ONE    - Require replication to one replica.
#   TWO    - Require replication to two replicas.
#   THREE  - Require replication to three replicas.
#   couchbase.replicate.to=NONE

# Any system property recognized by the Couchbase Java SDK may be specified
# here if you omit the "com." prefix from the system property name.
# For a list of system properties, see:
#   https://docs.couchbase.com/java-sdk/current/ref/client-settings.html#configuration-options
#
#couchbase.env.timeout.kvTimeout=3s

# The following *.converter properties are appropriate when reading from
# a topic whose messages have String (or null) keys and raw JSON values,
# without schemas. These are the correct settings to use with the code in
# the examples/json-producer directory.
key.converter=org.apache.kafka.connect.storage.StringConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
value.converter.schemas.enable=false

# If you're using Confluent, the Couchbase Sink Connector can also read
# messages published in the Avro format. Replace the above *.converter
# properties with the following (modifying the schema registry URL if needed):
#   key.converter=io.confluent.connect.avro.AvroConverter
#   key.converter.schema.registry.url=http://localhost:8081
#   value.converter=io.confluent.connect.avro.AvroConverter
#   value.converter.schema.registry.url=http://localhost:8081

# Optionally specify a time-to-live for documents written to Couchbase.
# If present, the value must be an integer followed by a time unit:
# (s = seconds, m = minutes, h = hours, d = days).
#   couchbase.document.expiration=30m

# If you're experimenting with the custom Single Message Transform from the
# example project, uncomment these lines:
#transforms=reverse,lowercase
#transforms.reverse.type=com.couchbase.connect.kafka.example.CustomTransform
#transforms.reverse.op=REVERSE
#transforms.lowercase.type=com.couchbase.connect.kafka.example.CustomTransform
#transforms.lowercase.op=LOWER_CASE
